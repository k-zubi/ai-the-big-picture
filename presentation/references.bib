@online{white_house_memorandum_2024,
    title = {Memorandum on Advancing the United States‚Äô Leadership in Artificial Intelligence; Harnessing Artificial Intelligence to Fulfill National Security Objectives; and Fostering the Safety, Security, and Trustworthiness of Artificial Intelligence},
    url = {https://bidenwhitehouse.archives.gov/briefing-room/presidential-actions/2024/10/24/memorandum-on-advancing-the-united-states-leadership-in-artificial-intelligence-harnessing-artificial-intelligence-to-fulfill-national-security-objectives-and-fostering-the-safety-security/},
    author = {{White House}},
    urldate = {2025-01-22},
    date = {2024-10-24},
    langid = {american},
}

@online{white_house_fact_sheet_2025,
    title = {FACT SHEET: Ensuring U.S. Security and Economic Strength in the Age of Artificial Intelligence},
    url = {https://bidenwhitehouse.archives.gov/briefing-room/statements-releases/2025/01/13/fact-sheet-ensuring-u-s-security-and-economic-strength-in-the-age-of-artificial-intelligence/},
    abstract = {Artificial intelligence is quickly becoming central to both security and economic strength. The United States must act decisively to lead this transition},
    author = {{White House}},
    urldate = {2025-01-22},
    date = {2025-01-13},
    langid = {american},
}

@online{white_house_statement_2025,
    title = {Statement by President Biden on the Executive Order on Advancing U.S. Leadership in Artificial Intelligence Infrastructure},
    url = {https://bidenwhitehouse.archives.gov/briefing-room/statements-releases/2025/01/14/statement-by-president-biden-on-the-executive-order-on-advancing-u-s-leadership-in-artificial-intelligence-infrastructure/},
    abstract = {The United States leads the world at the frontier of artificial intelligence ({AI}). Cutting-edge {AI} will have profound implications for national security},
    author = {{White House}},
    urldate = {2025-01-22},
    date = {2025-01-14},
    langid = {american},
}

@online{doug_burgum_senate_hearing_2025,
    title = {Hearing to Consider the Nomination of the Honorable Doug Burgum to be Secretary of the Interior},
    url = {https://www.energy.senate.gov/hearings/2025/1/hearing-to-consider-the-nomination-of-the-honorable-doug-burgum-to-be-secretary-of-the-interior},
    titleaddon = {U.S. Senate Committee on Energy and Natural Resources},
    author = {{U.S. Senate}},
    urldate = {2025-01-22},
    date = {2025-01-16},
    langid = {english},
}

@online{white_house_national_energy_emergency_2025,
    title = {Declaring a National Energy Emergency},
    url = {https://www.whitehouse.gov/presidential-actions/2025/01/declaring-a-national-energy-emergency/},
    abstract = {By the authority vested in me as President by the Constitution and the laws of the United States of America, including the National Emergencies Act (50},
    author = {{White House}},
    urldate = {2025-01-22},
    date = {2025-01-21},
    langid = {american},
}

@online{white_house_youtube_trump_infrastructure_remarks_2025,
    title = {President Trump Gives Remarks Regarding U.S. Infrastructure Investment},
    url = {https://www.youtube.com/watch?v=X5gMiDnYEds},
    author = {{White House}},
    urldate = {2025-01-22},
    date = {2025-01-21},
    langid = {english}
}

@online{epoch_ai_machine_learning_hardware_2024,
    title = {Data on Machine Learning Hardware},
    url = {https://epoch.ai/data/machine-learning-hardware},
    abstract = {We present key data on over 130 {AI} accelerators, such as graphics processing units ({GPUs}) and tensor processing units ({TPUs}), used to develop and deploy machine learning models in the deep learning era.},
    author = {{Epoch AI}},
    urldate = {2025-01-22},
    date = {2024-10-23},
    langid = {english},
}

@online{meta_louisiana_datacenter_facebook_2024,
    title = {Richland Parish Data Center},
    url = {https://www.facebook.com/RichlandParishDataCenter},
    author = {{Meta}},
    urldate = {2025-01-22},
    date = {2024-12-04},
    langid = {english},
}

@online{zuckerberg_louisiana_datacenter_2024,
    title = {Last big AI update of the year.},
    url = {https://www.instagram.com/zuck/reel/DDPm9gqv2cW/?hl=en},
    author = {Mark Zuckerberg},
    urldate = {2025-01-22},
    date = {2024-12-06},
    langid = {english},
}

@online{entergy_2025,
    title = {Entergy Louisiana to power Meta‚Äôs data center in Richland Parish},
    url = {https://www.entergynewsroom.com/news/entergy-louisiana-power-meta-s-data-center-in-richland-parish/},
    abstract = {Investment in new infrastructure will transform Northeast Louisiana economy for generations},
    author = {{Entergy}},
    urldate = {2025-01-22},
    date = {2024-12-05},
    langid = {english},
}

@online{governor_of_louisiana_2024,
    title = {Landry Announces Meta Selects North Louisiana as Site of \$10 Billion Artificial Intelligence Optimized Data Center {\textbar} Office of Governor Jeff Landry},
    url = {https://gov.louisiana.gov/news/4697},
    author = {{Governor of Louisiana}},
    urldate = {2025-01-22},
    date = {2024-12-04},
    langid = {english},
}

@online{boone_2025,
    title = {\$2.5 billion West Feliciana data center approved with 'aggressive timeline to build'},
    url = {https://www.theadvocate.com/baton_rouge/news/business/25-billion-west-feliciana-data-center-approved/article_d6dce702-cc45-11ef-8ff0-1fd2550a45e5.html},
    abstract = {The plan is to lease the center to an undisclosed tenant, which will then buy billions worth of computers and equipment.},
    author = {{Advocate}},
    urldate = {2025-01-22},
    date = {2025-01-06},
    langid = {english},
}

@online{murphy_criddle_2024,
    title = {Meta‚Äôs plan for nuclear-powered {AI} data centre thwarted by rare bees},
    url = {https://www.ft.com/content/ed602e09-6c40-4979-aff9-7453ee28406a},
    author = {{Financial Times}},
    date = {2024-11-04},
    urldate = {2025-01-22},
    langid = {english},
}

@online{copernicus_browser_2025,
    title = {Copernicus Browser},
    url = {https://browser.dataspace.copernicus.eu/},
    abstract = {Search, visualise and download Sentinel satellite imagery},
    titleaddon = {Copernicus Browser},
    author = {{Copernicus}},
    urldate = {2025-01-23},
    date = {2025-01-21},
    langid = {english},
}

@online{altman_big_beautiful_buildings_2025,
    title = {big. beautiful. buildings.},
    url = {https://x.com/sama/status/1882505650594611588?mx=2},
    titleaddon = {X},
    author = {Altman, Sam},
    urldate = {2025-01-25},
    date = {2025-01-23},
}

@online{microsoft_golden_2025,
    title = {The Golden Opportunity for American {AI}},
    url = {https://blogs.microsoft.com/on-the-issues/2025/01/03/the-golden-opportunity-for-american-ai/},
    abstract = {A golden opportunity lies ahead for America to harness the transformative power of {AI}‚Äîtoday‚Äôs electricity‚Äîto revolutionize the economy, secure global leadership, and build a foundation for prosperity through innovation, skilling, and international collaboration.},
    titleaddon = {Microsoft On the Issues},
    author = {{Microsoft}},
    urldate = {2025-01-28},
    date = {2025-01-03},
    langid = {american},
}

@online{zuckerberg_threads_2025,
    title = {Threads},
    url = {https://www.threads.net/@zuck/post/DFNf8bvpP2I},
    abstract = {We'll bring online {\textasciitilde}1GW of compute in '25 and we'll end the year with more than 1.3 million {GPUs}. We're planning to invest \$60-65B in capex this year while also growing our {AI} teams significantly, and we have the capital to continue investing in the years ahead. This is a massive effort, and over the coming years it will drive our core products and business, unlock historic innovation, and extend American technology leadership. Let's go build! üí™},
    author = {Zuckerberg, Mark},
    urldate = {2025-01-28},
    date = {2025-01-24},
}

@online{yahoo_finance_microsoft_2025,
    title = {Microsoft Corporation ({MSFT}) Analyst Ratings, Estimates \& Forecasts},
    url = {https://finance.yahoo.com/quote/MSFT/analysis/},
    abstract = {See Microsoft Corporation ({MSFT}) stock analyst estimates, including earnings and revenue, {EPS}, upgrades and downgrades.},
    titleaddon = {Yahoo Finance},
    author = {{Yahoo Finance}},
    urldate = {2025-01-28},
    date = {2025-01-28},
    langid = {american},
}

@online{meta_earnings_call_2025,
    title = {Meta Platforms ({META}) Q4 2024 Earnings Call Transcript},
    url = {https://www.fool.com/earnings/call-transcripts/2025/01/29/meta-platforms-meta-q4-2024-earnings-call-transcri/},
    abstract = {{META} earnings call for the period ending December 31, 2024.},
    titleaddon = {The Motley Fool},
    author = {{Meta}},
    urldate = {2025-02-01},
    date = {2025-01-29},
    langid = {english},
}

@misc{ho_algorithmic_2024,
    title = {Algorithmic progress in language models},
    url = {http://arxiv.org/abs/2403.05812},
    doi = {10.48550/arXiv.2403.05812},
    abstract = {We investigate the rate at which algorithms for pre-training language models have improved since the advent of deep learning. Using a dataset of over 200 language model evaluations on Wikitext and Penn Treebank spanning 2012-2023, we find that the compute required to reach a set performance threshold has halved approximately every 8 months, with a 95\% confidence interval of around 5 to 14 months, substantially faster than hardware gains per Moore's Law. We estimate augmented scaling laws, which enable us to quantify algorithmic progress and determine the relative contributions of scaling models versus innovations in training algorithms. Despite the rapid pace of algorithmic progress and the development of new architectures such as the transformer, our analysis reveals that the increase in compute made an even larger contribution to overall performance improvements over this time period. Though limited by noisy benchmark data, our analysis quantifies the rapid progress in language modeling, shedding light on the relative contributions from compute and algorithms.},
    number = {{arXiv}:2403.05812},
    publisher = {{arXiv}},
    author = {Ho, Anson and Besiroglu, Tamay and Erdil, Ege and Owen, David and Rahman, Robi and Guo, Zifan Carl and Atkinson, David and Thompson, Neil and Sevilla, Jaime},
    urldate = {2025-02-01},
    date = {2024-03-09},
    eprinttype = {arxiv},
    eprint = {2403.05812},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@online{epoch_notable_ai_models_2025,
    title = {Data on Notable {AI} Models},
    url = {https://epoch.ai/data/notable-ai-models},
    abstract = {Epoch {AI}‚Äôs database contains over 800 notable {ML} models and 400 training compute estimates, offering a detailed exploration of trends in {AI} development.},
    titleaddon = {Epoch {AI}},
    author = {{Epoch AI}},
    urldate = {2025-02-01},
    date = {2025-01-31},
    langid = {english},
}

@misc{kaplan_scaling_2020,
    title = {Scaling Laws for Neural Language Models},
    url = {http://arxiv.org/abs/2001.08361},
    doi = {10.48550/arXiv.2001.08361},
    abstract = {We study empirical scaling laws for language model performance on the cross-entropy loss. The loss scales as a power-law with model size, dataset size, and the amount of compute used for training, with some trends spanning more than seven orders of magnitude. Other architectural details such as network width or depth have minimal effects within a wide range. Simple equations govern the dependence of overfitting on model/dataset size and the dependence of training speed on model size. These relationships allow us to determine the optimal allocation of a fixed compute budget. Larger models are significantly more sample-efficient, such that optimally compute-efficient training involves training very large models on a relatively modest amount of data and stopping significantly before convergence.},
    number = {{arXiv}:2001.08361},
    publisher = {{arXiv}},
    author = {Kaplan, Jared and {McCandlish}, Sam and Henighan, Tom and Brown, Tom B. and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
    urldate = {2025-02-01},
    date = {2020-01-23},
    eprinttype = {arxiv},
    eprint = {2001.08361},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{hoffmann_training_2022,
    title = {Training Compute-Optimal Large Language Models},
    url = {http://arxiv.org/abs/2203.15556},
    doi = {10.48550/arXiv.2203.15556},
    abstract = {We investigate the optimal model size and number of tokens for training a transformer language model under a given compute budget. We find that current large language models are significantly undertrained, a consequence of the recent focus on scaling language models whilst keeping the amount of training data constant. By training over 400 language models ranging from 70 million to over 16 billion parameters on 5 to 500 billion tokens, we find that for compute-optimal training, the model size and the number of training tokens should be scaled equally: for every doubling of model size the number of training tokens should also be doubled. We test this hypothesis by training a predicted compute-optimal model, Chinchilla, that uses the same compute budget as Gopher but with 70B parameters and 4\${\textbackslash}times\$ more more data. Chinchilla uniformly and significantly outperforms Gopher (280B), {GPT}-3 (175B), Jurassic-1 (178B), and Megatron-Turing {NLG} (530B) on a large range of downstream evaluation tasks. This also means that Chinchilla uses substantially less compute for fine-tuning and inference, greatly facilitating downstream usage. As a highlight, Chinchilla reaches a state-of-the-art average accuracy of 67.5\% on the {MMLU} benchmark, greater than a 7\% improvement over Gopher.},
    number = {{arXiv}:2203.15556},
    publisher = {{arXiv}},
    author = {Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and Hennigan, Tom and Noland, Eric and Millican, Katie and Driessche, George van den and Damoc, Bogdan and Guy, Aurelia and Osindero, Simon and Simonyan, Karen and Elsen, Erich and Rae, Jack W. and Vinyals, Oriol and Sifre, Laurent},
    urldate = {2025-01-29},
    date = {2022-03-29},
    eprinttype = {arxiv},
    eprint = {2203.15556},
    keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{grattafiori_llama_2024,
    title = {The Llama 3 Herd of Models},
    url = {http://arxiv.org/abs/2407.21783},
    doi = {10.48550/arXiv.2407.21783},
    abstract = {Modern artificial intelligence ({AI}) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as {GPT}-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development.},
    number = {{arXiv}:2407.21783},
    publisher = {{arXiv}},
    author = {Grattafiori, Aaron and Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Vaughan, Alex and Yang, Amy and Fan, Angela and Goyal, Anirudh and Hartshorn, Anthony and Yang, Aobo and Mitra, Archi and Sravankumar, Archie and Korenev, Artem and Hinsvark, Arthur and Rao, Arun and Zhang, Aston and Rodriguez, Aurelien and Gregerson, Austen and Spataru, Ava and Roziere, Baptiste and Biron, Bethany and Tang, Binh and Chern, Bobbie and Caucheteux, Charlotte and Nayak, Chaya and Bi, Chloe and Marra, Chris and McConnell, Chris and Keller, Christian and Touret, Christophe and Wu, Chunyang and Wong, Corinne and Ferrer, Cristian Canton and Nikolaidis, Cyrus and Allonsius, Damien and Song, Daniel and Pintz, Danielle and Livshits, Danny and Wyatt, Danny and Esiobu, David and Choudhary, Dhruv and Mahajan, Dhruv and Garcia-Olano, Diego and Perino, Diego and Hupkes, Dieuwke and Lakomkin, Egor and AlBadawy, Ehab and Lobanova, Elina and Dinan, Emily and Smith, Eric Michael and Radenovic, Filip and Guzm√°n, Francisco and Zhang, Frank and Synnaeve, Gabriel and Lee, Gabrielle and Anderson, Georgia Lewis and Thattai, Govind and Nail, Graeme and Mialon, Gregoire and Pang, Guan and Cucurell, Guillem and Nguyen, Hailey and Korevaar, Hannah and Xu, Hu and Touvron, Hugo and Zarov, Iliyan and Ibarra, Imanol Arrieta and Kloumann, Isabel and Misra, Ishan and Evtimov, Ivan and Zhang, Jack and Copet, Jade and Lee, Jaewon and Geffert, Jan and Vranes, Jana and Park, Jason and Mahadeokar, Jay and Shah, Jeet and Linde, Jelmer van der and Billock, Jennifer and Hong, Jenny and Lee, Jenya and Fu, Jeremy and Chi, Jianfeng and Huang, Jianyu and Liu, Jiawen and Wang, Jie and Yu, Jiecao and Bitton, Joanna and Spisak, Joe and Park, Jongsoo and Rocca, Joseph and Johnstun, Joshua and Saxe, Joshua and Jia, Junteng and Alwala, Kalyan Vasuden and Prasad, Karthik and Upasani, Kartikeya and Plawiak, Kate and Li, Ke and Heafield, Kenneth and Stone, Kevin and El-Arini, Khalid and Iyer, Krithika and Malik, Kshitiz and Chiu, Kuenley and Bhalla, Kunal and Lakhotia, Kushal and Rantala-Yeary, Lauren and Maaten, Laurens van der and Chen, Lawrence and Tan, Liang and Jenkins, Liz and Martin, Louis and Madaan, Lovish and Malo, Lubo and Blecher, Lukas and Landzaat, Lukas and Oliveira, Luke de and Muzzi, Madeline and Pasupuleti, Mahesh and Singh, Mannat and Paluri, Manohar and Kardas, Marcin and Tsimpoukelli, Maria and Oldham, Mathew and Rita, Mathieu and Pavlova, Maya and Kambadur, Melanie and Lewis, Mike and Si, Min and Singh, Mitesh Kumar and Hassan, Mona and Goyal, Naman and Torabi, Narjes and Bashlykov, Nikolay and Bogoychev, Nikolay and Chatterji, Niladri and Zhang, Ning and Duchenne, Olivier and √áelebi, Onur and Alrassy, Patrick and Zhang, Pengchuan and Li, Pengwei and Vasic, Petar and Weng, Peter and Bhargava, Prajjwal and Dubal, Pratik and Krishnan, Praveen and Koura, Punit Singh and Xu, Puxin and He, Qing and Dong, Qingxiao and Srinivasan, Ragavan and Ganapathy, Raj and Calderer, Ramon and Cabral, Ricardo Silveira and Stojnic, Robert and Raileanu, Roberta and Maheswari, Rohan and Girdhar, Rohit and Patel, Rohit and Sauvestre, Romain and Polidoro, Ronnie and Sumbaly, Roshan and Taylor, Ross and Silva, Ruan and Hou, Rui and Wang, Rui and Hosseini, Saghar and Chennabasappa, Sahana and Singh, Sanjay and Bell, Sean and Kim, Seohyun Sonia and Edunov, Sergey and Nie, Shaoliang and Narang, Sharan and Raparthy, Sharath and Shen, Sheng and Wan, Shengye and Bhosale, Shruti and Zhang, Shun and Vandenhende, Simon and Batra, Soumya and Whitman, Spencer and Sootla, Sten and Collot, Stephane and Gururangan, Suchin and Borodinsky, Sydney and Herman, Tamar and Fowler, Tara and Sheasha, Tarek and Georgiou, Thomas and Scialom, Thomas and Speckbacher, Tobias and Mihaylov, Todor and Xiao, Tong and Karn, Ujjwal and Goswami, Vedanuj and Gupta, Vibhor and Ramanathan, Vignesh and Kerkez, Viktor and Gonguet, Vincent and Do, Virginie and Vogeti, Vish and Albiero, V√≠tor and Petrovic, Vladan and Chu, Weiwei and Xiong, Wenhan and Fu, Wenyin and Meers, Whitney and Martinet, Xavier and Wang, Xiaodong and Wang, Xiaofang and Tan, Xiaoqing Ellen and Xia, Xide and Xie, Xinfeng and Jia, Xuchao and Wang, Xuewei and Goldschlag, Yaelle and Gaur, Yashesh and Babaei, Yasmine and Wen, Yi and Song, Yiwen and Zhang, Yuchen and Li, Yue and Mao, Yuning and Coudert, Zacharie Delpierre and Yan, Zheng and Chen, Zhengxing and Papakipos, Zoe and Singh, Aaditya and Srivastava, Aayushi and Jain, Abha and Kelsey, Adam and Shajnfeld, Adam and Gangidi, Adithya and Victoria, Adolfo and Goldstand, Ahuva and Menon, Ajay and Sharma, Ajay and Boesenberg, Alex and Baevski, Alexei and Feinstein, Allie and Kallet, Amanda and Sangani, Amit and Teo, Amos and Yunus, Anam and Lupu, Andrei and Alvarado, Andres and Caples, Andrew and Gu, Andrew and Ho, Andrew and Poulton, Andrew and Ryan, Andrew and Ramchandani, Ankit and Dong, Annie and Franco, Annie and Goyal, Anuj and Saraf, Aparajita and Chowdhury, Arkabandhu and Gabriel, Ashley and Bharambe, Ashwin and Eisenman, Assaf and Yazdan, Azadeh and James, Beau and Maurer, Ben and Leonhardi, Benjamin and Huang, Bernie and Loyd, Beth and Paola, Beto De and Paranjape, Bhargavi and Liu, Bing and Wu, Bo and Ni, Boyu and Hancock, Braden and Wasti, Bram and Spence, Brandon and Stojkovic, Brani and Gamido, Brian and Montalvo, Britt and Parker, Carl and Burton, Carly and Mejia, Catalina and Liu, Ce and Wang, Changhan and Kim, Changkyu and Zhou, Chao and Hu, Chester and Chu, Ching-Hsiang and Cai, Chris and Tindal, Chris and Feichtenhofer, Christoph and Gao, Cynthia and Civin, Damon and Beaty, Dana and Kreymer, Daniel and Li, Daniel and Adkins, David and Xu, David and Testuggine, Davide and David, Delia and Parikh, Devi and Liskovich, Diana and Foss, Didem and Wang, Dingkang and Le, Duc and Holland, Dustin and Dowling, Edward and Jamil, Eissa and Montgomery, Elaine and Presani, Eleonora and Hahn, Emily and Wood, Emily and Le, Eric-Tuan and Brinkman, Erik and Arcaute, Esteban and Dunbar, Evan and Smothers, Evan and Sun, Fei and Kreuk, Felix and Tian, Feng and Kokkinos, Filippos and Ozgenel, Firat and Caggioni, Francesco and Kanayet, Frank and Seide, Frank and Florez, Gabriela Medina and Schwarz, Gabriella and Badeer, Gada and Swee, Georgia and Halpern, Gil and Herman, Grant and Sizov, Grigory and {Guangyi} and {Zhang} and Lakshminarayanan, Guna and Inan, Hakan and Shojanazeri, Hamid and Zou, Han and Wang, Hannah and Zha, Hanwen and Habeeb, Haroun and Rudolph, Harrison and Suk, Helen and Aspegren, Henry and Goldman, Hunter and Zhan, Hongyuan and Damlaj, Ibrahim and Molybog, Igor and Tufanov, Igor and Leontiadis, Ilias and Veliche, Irina-Elena and Gat, Itai and Weissman, Jake and Geboski, James and Kohli, James and Lam, Janice and Asher, Japhet and Gaya, Jean-Baptiste and Marcus, Jeff and Tang, Jeff and Chan, Jennifer and Zhen, Jenny and Reizenstein, Jeremy and Teboul, Jeremy and Zhong, Jessica and Jin, Jian and Yang, Jingyi and Cummings, Joe and Carvill, Jon and Shepard, Jon and McPhie, Jonathan and Torres, Jonathan and Ginsburg, Josh and Wang, Junjie and Wu, Kai and U, Kam Hou and Saxena, Karan and Khandelwal, Kartikay and Zand, Katayoun and Matosich, Kathy and Veeraraghavan, Kaushik and Michelena, Kelly and Li, Keqian and Jagadeesh, Kiran and Huang, Kun and Chawla, Kunal and Huang, Kyle and Chen, Lailin and Garg, Lakshya and A, Lavender and Silva, Leandro and Bell, Lee and Zhang, Lei and Guo, Liangpeng and Yu, Licheng and Moshkovich, Liron and Wehrstedt, Luca and Khabsa, Madian and Avalani, Manav and Bhatt, Manish and Mankus, Martynas and Hasson, Matan and Lennie, Matthew and Reso, Matthias and Groshev, Maxim and Naumov, Maxim and Lathi, Maya and Keneally, Meghan and Liu, Miao and Seltzer, Michael L. and Valko, Michal and Restrepo, Michelle and Patel, Mihir and Vyatskov, Mik and Samvelyan, Mikayel and Clark, Mike and Macey, Mike and Wang, Mike and Hermoso, Miquel Jubert and Metanat, Mo and Rastegari, Mohammad and Bansal, Munish and Santhanam, Nandhini and Parks, Natascha and White, Natasha and Bawa, Navyata and Singhal, Nayan and Egebo, Nick and Usunier, Nicolas and Mehta, Nikhil and Laptev, Nikolay Pavlovich and Dong, Ning and Cheng, Norman and Chernoguz, Oleg and Hart, Olivia and Salpekar, Omkar and Kalinli, Ozlem and Kent, Parkin and Parekh, Parth and Saab, Paul and Balaji, Pavan and Rittner, Pedro and Bontrager, Philip and Roux, Pierre and Dollar, Piotr and Zvyagina, Polina and Ratanchandani, Prashant and Yuvraj, Pritish and Liang, Qian and Alao, Rachad and Rodriguez, Rachel and Ayub, Rafi and Murthy, Raghotham and Nayani, Raghu and Mitra, Rahul and Parthasarathy, Rangaprabhu and Li, Raymond and Hogan, Rebekkah and Battey, Robin and Wang, Rocky and Howes, Russ and Rinott, Ruty and Mehta, Sachin and Siby, Sachin and Bondu, Sai Jayesh and Datta, Samyak and Chugh, Sara and Hunt, Sara and Dhillon, Sargun and Sidorov, Sasha and Pan, Satadru and Mahajan, Saurabh and Verma, Saurabh and Yamamoto, Seiji and Ramaswamy, Sharadh and Lindsay, Shaun and Lindsay, Shaun and Feng, Sheng and Lin, Shenghao and Zha, Shengxin Cindy and Patil, Shishir and Shankar, Shiva and Zhang, Shuqiang and Zhang, Shuqiang and Wang, Sinong and Agarwal, Sneha and Sajuyigbe, Soji and Chintala, Soumith and Max, Stephanie and Chen, Stephen and Kehoe, Steve and Satterfield, Steve and Govindaprasad, Sudarshan and Gupta, Sumit and Deng, Summer and Cho, Sungmin and Virk, Sunny and Subramanian, Suraj and Choudhury, Sy and Goldman, Sydney and Remez, Tal and Glaser, Tamar and Best, Tamara and Koehler, Thilo and Robinson, Thomas and Li, Tianhe and Zhang, Tianjun and Matthews, Tim and Chou, Timothy and Shaked, Tzook and Vontimitta, Varun and Ajayi, Victoria and Montanez, Victoria and Mohan, Vijai and Kumar, Vinay Satish and Mangla, Vishal and Ionescu, Vlad and Poenaru, Vlad and Mihailescu, Vlad Tiberiu and Ivanov, Vladimir and Li, Wei and Wang, Wenchen and Jiang, Wenwen and Bouaziz, Wes and Constable, Will and Tang, Xiaocheng and Wu, Xiaojian and Wang, Xiaolan and Wu, Xilun and Gao, Xinbo and Kleinman, Yaniv and Chen, Yanjun and Hu, Ye and Jia, Ye and Qi, Ye and Li, Yenda and Zhang, Yilin and Zhang, Ying and Adi, Yossi and Nam, Youngjin and {Yu} and {Wang} and Zhao, Yu and Hao, Yuchen and Qian, Yundi and Li, Yunlu and He, Yuzi and Rait, Zach and DeVito, Zachary and Rosnbrick, Zef and Wen, Zhaoduo and Yang, Zhenyu and Zhao, Zhiwei and Ma, Zhiyu},
    urldate = {2025-02-01},
    date = {2024-11-23},
    eprinttype = {arxiv},
    eprint = {2407.21783},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
}

@misc{stromnetz_berlin_faktenblatt_2024,
    title = {Faktenblatt - Stromnetz Berlin {GmbH}},
    url = {https://www.stromnetz.berlin/files/globalassets/dokumente/presse/faktenblatt-stromnetz-berlin.pdf},
    author = {{Stromnetz Berlin}},
    date = {2024-07-17},
}

@online{swissgrid_netzlast_2025,
    title = {Netzlast},
    url = {https://www.swissgrid.ch/de/home/operation/grid-data/load.html},
    abstract = {Interessante Messdaten rund um das Thema Netzlast im Schweizer √úbertragungsnetz.},
    author = {{Swissgrid}},
    urldate = {2025-02-06},
    date = {2025-01-31},
    langid = {german},
}

@online{the_information_stargate_2024,
    title = {Microsoft and {OpenAI} Plot \$100 Billion Stargate {AI} Supercomputer},
    url = {https://www.theinformation.com/articles/microsoft-and-openai-plot-100-billion-stargate-ai-supercomputer},
    abstract = {Interessante Messdaten rund um das Thema Netzlast im Schweizer √úbertragungsnetz.},
    author = {{The Information}},
    urldate = {2025-02-06},
    date = {2024-03-29},
}

@online{patel_transcript_2025,
    title = {Transcript for {DeepSeek}, China, {OpenAI}, {NVIDIA}, {xAI}, {TSMC}, Stargate, and {AI} Megaclusters {\textbar} Lex Fridman Podcast \#459},
    url = {https://lexfridman.com/deepseek-dylan-patel-nathan-lambert-transcript/},
    abstract = {This is a transcript of Lex Fridman Podcast \#459 with Dylan Patel and Nathan Lambert. The timestamps in the transcript are clickable links that take you directly to that point in the main video. Please note that the transcript is human generated, and may have errors. Here are some useful links: Go back to this episode‚Äôs main page Watch the full {YouTube} version of the podcast Table of Contents Here are the loose ‚Äúchapters‚Äù in the conversation. Click link to jump approximately to that part in the transcript: 3:33 ‚Äì {DeepSeek}-R1 and {DeepSeek}-V3 25:07 ‚Äì Low cost of training 51:25},
    titleaddon = {Lex Fridman},
    author = {Patel, Dylan},
    urldate = {2025-02-06},
    date = {2025-02-03},
    langid = {american},
}

@inproceedings{radford_language_2019,
    title = {Language Models are Unsupervised Multitask Learners},
    url = {https://www.semanticscholar.org/paper/Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu/9405cc0d6169988371b2755e573cc28650d14dfe},
    abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called {WebText}. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the {CoQA} dataset matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, {GPT}-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits {WebText}. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
    author = {Radford, Alec and Wu, Jeff and Child, R. and Luan, D. and Amodei, Dario and Sutskever, I.},
    urldate = {2025-02-06},
    date = {2019},
}

@misc{openai_o1_system_card_2024,
    title = {{OpenAI} o1 System Card},
    url = {http://arxiv.org/abs/2412.16720},
    doi = {10.48550/arXiv.2412.16720},
    abstract = {The o1 model series is trained with large-scale reinforcement learning to reason using chain of thought. These advanced reasoning capabilities provide new avenues for improving the safety and robustness of our models. In particular, our models can reason about our safety policies in context when responding to potentially unsafe prompts, through deliberative alignment. This leads to state-of-the-art performance on certain benchmarks for risks such as generating illicit advice, choosing stereotyped responses, and succumbing to known jailbreaks. Training models to incorporate a chain of thought before answering has the potential to unlock substantial benefits, while also increasing potential risks that stem from heightened intelligence. Our results underscore the need for building robust alignment methods, extensively stress-testing their efficacy, and maintaining meticulous risk management protocols. This report outlines the safety work carried out for the {OpenAI} o1 and {OpenAI} o1-mini models, including safety evaluations, external red teaming, and Preparedness Framework evaluations.},
    number = {{arXiv}:2412.16720},
    publisher = {{arXiv}},
    author = {{OpenAI}},
    urldate = {2025-02-06},
    date = {2024-12-21},
    eprinttype = {arxiv},
    eprint = {2412.16720},
    keywords = {Computer Science - Artificial Intelligence},
}

@misc{wei_finetuned_2021,
    title = {Finetuned Language Models Are Zero-Shot Learners},
    url = {http://arxiv.org/abs/2109.01652},
    doi = {10.48550/arXiv.2109.01652},
    abstract = {This paper explores a simple method for improving the zero-shot learning abilities of language models. We show that instruction tuning -- finetuning language models on a collection of tasks described via instructions -- substantially boosts zero-shot performance on unseen tasks. We take a 137B parameter pretrained language model and instruction-tune it on over 60 {NLP} tasks verbalized via natural language instruction templates. We evaluate this instruction-tuned model, which we call {FLAN}, on unseen task types. {FLAN} substantially improves the performance of its unmodified counterpart and surpasses zero-shot 175B {GPT}-3 on 19 of 25 tasks that we evaluate. {FLAN} even outperforms few-shot {GPT}-3 by a large margin on {ANLI}, {RTE}, {BoolQ}, {AI}2-{ARC}, {OpenbookQA}, and {StoryCloze}. Ablation studies reveal that number of tasks and model scale are key components to the success of instruction tuning.},
    number = {{arXiv}:2109.01652},
    publisher = {{arXiv}},
    author = {Wei, Jason and Bosma, Maarten and Zhao, Vincent Y. and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M. and Le, Quoc V.},
    urldate = {2025-02-06},
    date = {2021-09-03},
    eprinttype = {arxiv},
    eprint = {2109.01652},
    note = {version: 1},
    keywords = {Computer Science - Computation and Language},
}

@misc{ouyang_training_2022,
    title = {Training language models to follow instructions with human feedback},
    url = {http://arxiv.org/abs/2203.02155},
    doi = {10.48550/arXiv.2203.02155},
    abstract = {Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through the {OpenAI} {API}, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune {GPT}-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models {InstructGPT}. In human evaluations on our prompt distribution, outputs from the 1.3B parameter {InstructGPT} model are preferred to outputs from the 175B {GPT}-3, despite having 100x fewer parameters. Moreover, {InstructGPT} models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public {NLP} datasets. Even though {InstructGPT} still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.},
    number = {{arXiv}:2203.02155},
    publisher = {{arXiv}},
    author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L. and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
    urldate = {2025-02-06},
    date = {2022-03-04},
    eprinttype = {arxiv},
    eprint = {2203.02155},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{shumailov2024curserecursiontraininggenerated,
    title = {The Curse of Recursion: Training on Generated Data Makes Models Forget},
    author = {Ilia Shumailov and Zakhar Shumaylov and Yiren Zhao and Yarin Gal and Nicolas Papernot and Ross Anderson},
    year = {2023},
    eprint = {2305.17493},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2305.17493}
}

@misc{epoch2023tradingoffcomputeintrainingandinference,
    title = {Trading Off Compute in Training and Inference},
    author = {Pablo Villalobos and David Atkinson},
    year = {2023},
    url = {https://epoch.ai/blog/trading-off-compute-in-training-and-inference},
    urldate = {2025-02-06},
}

@misc{feng2024modelcollapsescalingsynthesized,
    title = {Beyond Model Collapse: Scaling Up with Synthesized Data Requires Verification},
    author = {Yunzhen Feng and Elvis Dohmatob and Pu Yang and Francois Charton and Julia Kempe},
    year = {2024},
    eprint = {2406.07515},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url = {https://arxiv.org/abs/2406.07515},
}

@online{erdil_deepseek_2025,
    title = {What went into training {DeepSeek}-R1?},
    url = {https://epoch.ai/gradient-updates/what-went-into-training-deepseek-r1},
    abstract = {This Gradient Updates issue explores {DeepSeek}-R1‚Äôs architecture, training cost, and pricing, showing how it rivals {OpenAI}‚Äôs o1 at 30x lower cost.},
    titleaddon = {Epoch {AI}},
    author = {Erdil, Ege},
    urldate = {2025-02-07},
    date = {2025-01-31},
    langid = {english},
}

@misc{pan2024trainingsoftwareengineeringagents,
    title = {Training Software Engineering Agents and Verifiers with SWE-Gym},
    author = {Jiayi Pan and Xingyao Wang and Graham Neubig and Navdeep Jaitly and Heng Ji and Alane Suhr and Yizhe Zhang},
    year = {2024},
    eprint = {2412.21139},
    archivePrefix = {arXiv},
    primaryClass = {cs.SE},
    url = {https://arxiv.org/abs/2412.21139},
}

@misc{hu2024agentgenenhancingplanningabilities,
    title = {AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation},
    author = {Mengkang Hu and Pu Zhao and Can Xu and Qingfeng Sun and Jianguang Lou and Qingwei Lin and Ping Luo and Saravan Rajmohan},
    year = {2024},
    eprint = {2408.00764},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL},
    url = {https://arxiv.org/abs/2408.00764},
}

@misc{xu2024theagentcompanybenchmarkingllmagents,
    title = {TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks},
    author = {Frank F. Xu and Yufan Song and Boxuan Li and Yuxuan Tang and Kritanjali Jain and Mengxue Bao and Zora Z. Wang and Xuhui Zhou and Zhitong Guo and Murong Cao and Mingyang Yang and Hao Yang Lu and Amaad Martin and Zhe Su and Leander Maben and Raj Mehta and Wayne Chi and Lawrence Jang and Yiqing Xie and Shuyan Zhou and Graham Neubig},
    year = {2024},
    eprint = {2412.14161},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL},
    url = {https://arxiv.org/abs/2412.14161},
}

@misc{epoch2024canaiscalingcontinuethrough2030,
    title = {Can AI Scaling Continue Through 2030?},
    author = {Jaime Sevilla and Tamay Besiroglu and Ben Cottier and Josh You and Edu Rold√°n and Pablo Villalobos and Ege Erdil},
    year = {2024},
    url = {https://epoch.ai/blog/can-ai-scaling-continue-through-2030},
}

@misc{valmeekam2024llmscantplanlrms,
    title = {LLMs Still Can't Plan; Can LRMs? A Preliminary Evaluation of OpenAI's o1 on PlanBench},
    author = {Karthik Valmeekam and Kaya Stechly and Subbarao Kambhampati},
    year = {2024},
    eprint = {2409.13373},
    archivePrefix = {arXiv},
    primaryClass = {cs.AI},
    url = {https://arxiv.org/abs/2409.13373},
}

@misc{OSWorld,
    title = {OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments},
    author = {Tianbao Xie and Danyang Zhang and Jixuan Chen and Xiaochuan Li and Siheng Zhao and Ruisheng Cao and Toh Jing Hua and Zhoujun Cheng and Dongchan Shin and Fangyu Lei and Yitao Liu and Yiheng Xu and Shuyan Zhou and Silvio Savarese and Caiming Xiong and Victor Zhong and Tao Yu},
    year = {2024},
    eprint = {2404.07972},
    archivePrefix = {arXiv},
    primaryClass = {cs.AI}
}

@misc{mialon2023gaia,
    title = {GAIA: a benchmark for General AI Assistants},
    author = {Gr√©goire Mialon and Cl√©mentine Fourrier and Craig Swift and Thomas Wolf and Yann LeCun and Thomas Scialom},
    year = {2023},
    eprint = {2311.12983},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL}
}

@online{chollet_o3_2024,
    title = {{OpenAI} o3 Breakthrough High Score on {ARC}-{AGI}-Pub},
    url = {https://arcprize.org/blog/oai-o3-pub-breakthrough},
    abstract = {{OpenAI} o3 scores 75.7\% on {ARC}-{AGI} public leaderboard.},
    titleaddon = {{ARC} Prize},
    author = {Chollet, Fran√ßois},
    urldate = {2025-02-08},
    date = {2024-12-20},
    langid = {english},
}

@misc{legris2024harcrobustestimatehuman,
    title = {H-ARC: A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark},
    author = {Solim LeGris and Wai Keen Vong and Brenden M. Lake and Todd M. Gureckis},
    year = {2024},
    eprint = {2409.01374},
    archivePrefix = {arXiv},
    primaryClass = {cs.AI},
    url = {https://arxiv.org/abs/2409.01374},
}

@online{openai_deep_research_2025,
    title = {Introducing deep research},
    url = {https://openai.com/index/introducing-deep-research/},
    abstract = {An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research tasks for you. Available to Pro users today, Plus and Team next.},
    author = {{OpenAI}},
    urldate = {2025-02-08},
    date = {2025-02-02},
}

@online{white_house_farewell_address_2025,
    title = {Remarks by President Biden in a Farewell Address to the Nation},
    url = {https://bidenwhitehouse.archives.gov/briefing-room/speeches-remarks/2025/01/15/remarks-by-president-biden-in-a-farewell-address-to-the-nation/},
    titleaddon = {The White House},
    author = {{White House}},
    urldate = {2025-02-08},
    date = {2025-01-16},
    langid = {american},
}

@inproceedings{NIPS2012_c399862d,
    author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
    pages = {},
    publisher = {Curran Associates, Inc.},
    title = {ImageNet Classification with Deep Convolutional Neural Networks},
    url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
    volume = {25},
    year = {2012}
}

@online{cerebras_wse_3_2024,
    title = {Cerebras Systems Unveils World‚Äôs Fastest {AI} Chip with Whopping 4 Trillion Transistors},
    url = {https://cerebras.ai/press-release/cerebras-announces-third-generation-wafer-scale-engine/},
    abstract = {Third Generation 5nm Wafer Scale Engine ({WSE}-3) Powers Industry‚Äôs Most Scalable {AI} Supercomputers, Up To 256 {exaFLOPs} via 2048 Nodes},
    titleaddon = {Cerebras},
    author = {{Cerebras}},
    urldate = {2025-02-08},
    date = {2024-03-11},
    langid = {american},
}

@online{groq_groqrack_2024,
    title = {{GroqRack} - Groq is Fast {AI} Inference},
    url = {https://groq.com/groqrack/},
    abstract = {Take your own cloud or {AI} Compute Center to the next level with on-prem deployments. Groq {LPU}‚Ñ¢ {AI} inference technology is available in various interconnected},
    author = {{Groq}},
    urldate = {2025-02-08},
    date = {2024-06-28},
    langid = {american},
}

@online{etched_announcement_2024,
    title = {Etched is Making the Biggest Bet in {AI}},
    url = {https://www.etched.com/announcing-etched},
    author = {{Etched}},
    urldate = {2025-02-08},
    date = {2024-06-25},
    langid = {english},
}

@misc{epoch2024trainingcomputeoffrontieraimodelsgrowsby45xperyear,
    title = {Training Compute of Frontier AI Models Grows by 4-5x per Year},
    author = {Jaime Sevilla and Edu Rold√°n},
    year = {2024},
    url = {https://epoch.ai/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year},
    note = {Accessed: 2025-02-08}
}

@online{nvidia_gb200_nvl72_2025,
    title = {{NVIDIA} {GB}200 {NVL}72 {GPU} ‚Äì Optimized for {AI} and Data Centers},
    url = {https://www.nvidia.com/en-us/data-center/gb200-nvl72/},
    abstract = {Discover the powerful {GB}200 {NVL}72 {GPU}, engineered for {AI} workloads and next-gen data centers.},
    titleaddon = {{NVIDIA}},
    author = {{NVIDIA}},
    urldate = {2025-02-08},
    date = {2025-02-09},
    langid = {english},
}

@online{tweaktown_amazon_2024,
    title = {Amazon teases its next-gen Trainium3 {AI} accelerator is 4x faster than Trainium 3, drops in 2025},
    url = {https://www.tweaktown.com/news/102010/amazon-teases-its-next-gen-trainium3-ai-accelerator-is-4x-faster-than-trainium-3-drops-in-2025/index.html},
    abstract = {Amazon {AWS} teases its next-gen Trainium3 {AI} accelerator chip: 4x higher performance than Trainium2, using {TSMC} 3nm process, expected in 2025.},
    titleaddon = {{TweakTown}},
    author = {{TweakTown}},
    urldate = {2025-02-08},
    date = {2024-12-04},
    langid = {american},
}

@online{google_tpu_2024,
    title = {{TPU} transformation: A look back at 10 years of our {AI}-specialized chips},
    url = {https://cloud.google.com/transform/ai-specialized-chips-tpu-history-gen-ai},
    shorttitle = {{TPU} transformation},
    abstract = {Google has been a leader on {AI} development for more than a decade by also being a leader in chip development for more than a decade.},
    titleaddon = {Google Cloud Blog},
    author = {{Google}},
    urldate = {2025-02-09},
    date = {2024-07-31},
    langid = {american},
}

@online{microsoft_azure_maia_2023,
    title = {With a systems approach to chips, Microsoft aims to tailor everything ‚Äòfrom silicon to service‚Äô to meet {AI} demand},
    url = {https://news.microsoft.com/source/features/ai/in-house-chips-silicon-to-service-to-meet-ai-demand/},
    abstract = {Microsoft unveils two custom chips, new industry partnerships and a systems approach to Azure hardware optimized for internal and customer workloads},
    titleaddon = {Microsoft},
    author = {{Microsoft}},
    urldate = {2025-02-09},
    date = {2023-11-15},
    langid = {american},
}

@online{meta_mtia_2024,
    title = {Our next-generation Meta Training and Inference Accelerator},
    url = {https://ai.meta.com/blog/next-generation-meta-training-inference-accelerator-AI-MTIA/},
    author = {{Meta}},
    urldate = {2025-02-09},
    date = {2024-04-10},
}

@online{data_center_dynamics_susquehanna_2025,
    title = {Susquehanna Nuclear challenges {FERC} rejection of connection agreement to power {AWS} data center},
    url = {https://www.datacenterdynamics.com/en/news/susquehanna-nuclear-challenges-ferc-rejection-of-connection-agreement-to-power-aws-data-center/},
    abstract = {Seeks review of rejected {ISA} for power increase between nuclear plant and data center campus},
    author = {{Data Center Dynamics}},
    urldate = {2025-02-09},
    date = {2025-01-25},
    langid = {english},
}

@article{le_monde_intelligence_2025,
    title = {Intelligence artificielle : Emmanuel Macron annonce des investissements en France de '109 milliards d‚Äôeuros dans les prochaines ann√©es'},
    url = {https://www.lemonde.fr/pixels/article/2025/02/09/intelligence-artificielle-emmanuel-macron-annonce-des-investissements-en-france-de-109-milliards-d-euros-dans-les-prochaines-annees_6539115_4408996.html},
    shorttitle = {Intelligence artificielle},
    author = {{Le Monde}},
    urldate = {2025-02-09},
    date = {2025-02-09},
    langid = {french},
}

@online{data_center_dynamics_france_2025,
    title = {France and {UAE} to invest billions into 1GW European {AI} data center},
    url = {https://www.datacenterdynamics.com/en/news/france-and-uae-to-invest-billions-into-1gw-european-ai-data-center/},
    abstract = {Joint project will boost French {AI} infrastructure},
    author = {{Data Center Dynamics}},
    urldate = {2025-02-09},
    date = {2025-02-07},
    langid = {english},
}

@misc{deepscaler2025,
    title = {DeepScaleR: Surpassing O1-Preview with a 1.5B Model by Scaling RL},
    author = {Michael Luo and Sijun Tan and Justin Wong and Xiaoxiang Shi and William Y. Tang and Manan Roongta and Colin Cai and Jeffrey Luo and Tianjun Zhang and Li Erran Li and Raluca Ada Popa and Ion Stoica},
    howpublished = {\url{https://pretty-radio-b75.notion.site/DeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Model-by-Scaling-RL-19681902c1468005bed8ca303013a4e2}},
    note = {Notion Blog},
    year = {2025}
}

@misc{deepseekai2025,
    title = {DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
    author = {Daya Guo and Dejian Yang and Haowei Zhang and Junxiao Song and Ruoyu Zhang and Runxin Xu and Qihao Zhu and Shirong Ma and Peiyi Wang and Xiao Bi and Xiaokang Zhang and Xingkai Yu and Yu Wu and Z. F. Wu and Zhibin Gou and Zhihong Shao and Zhuoshu Li and Ziyi Gao and Aixin Liu and Bing Xue and Bingxuan Wang and Bochao Wu and Bei Feng and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Qu and Hui Li and Jianzhong Guo and Jiashi Li and Jiawei Wang and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and J. L. Cai and Jiaqi Ni and Jian Liang and Jin Chen and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Liang Zhao and Litong Wang and Liyue Zhang and Lei Xu and Leyi Xia and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Meng Li and Miaojun Wang and Mingming Li and Ning Tian and Panpan Huang and Peng Zhang and Qiancheng Wang and Qinyu Chen and Qiushi Du and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and R. J. Chen and R. L. Jin and Ruyi Chen and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shengfeng Ye and Shiyu Wang and Shuiping Yu and Shunfeng Zhou and Shuting Pan and S. S. Li and Shuang Zhou and Shaoqing Wu and Shengfeng Ye and Tao Yun and Tian Pei and Tianyu Sun and T. Wang and Wangding Zeng and Wanjia Zhao and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and W. L. Xiao and Wei An and Xiaodong Liu and Xiaohan Wang and Xiaokang Chen and Xiaotao Nie and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and X. Q. Li and Xiangyue Jin and Xiaojin Shen and Xiaosha Chen and Xiaowen Sun and Xiaoxiang Wang and Xinnan Song and Xinyi Zhou and Xianzu Wang and Xinxia Shan and Y. K. Li and Y. Q. Wang and Y. X. Wei and Yang Zhang and Yanhong Xu and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Wang and Yi Yu and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma and Yiyuan Liu and Yongqiang Guo and Yuan Ou and Yuduan Wang and Yue Gong and Yuheng Zou and Yujia He and Yunfan Xiong and Yuxiang Luo and Yuxiang You and Yuxuan Liu and Yuyang Zhou and Y. X. Zhu and Yanhong Xu and Yanping Huang and Yaohui Li and Yi Zheng and Yuchen Zhu and Yunxian Ma and Ying Tang and Yukun Zha and Yuting Yan and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhenda Xie and Zhengyan Zhang and Zhewen Hao and Zhicheng Ma and Zhigang Yan and Zhiyu Wu and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and Ziwei Xie and Ziyang Song and Zizheng Pan and Zhen Huang and Zhipeng Xu and Zhongyu Zhang and Zhen Zhang},
    year = {2025},
    eprint = {2501.12948},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL},
    url = {https://arxiv.org/abs/2501.12948},
}

@misc{xu2025largereasoningmodelssurvey,
    title = {Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models},
    author = {Fengli Xu and Qianyue Hao and Zefang Zong and Jingwei Wang and Yunke Zhang and Jingyi Wang and Xiaochong Lan and Jiahui Gong and Tianjian Ouyang and Fanjin Meng and Chenyang Shao and Yuwei Yan and Qinglong Yang and Yiwen Song and Sijian Ren and Xinyuan Hu and Yu Li and Jie Feng and Chen Gao and Yong Li},
    year = {2025},
    eprint = {2501.09686},
    archivePrefix = {arXiv},
    primaryClass = {cs.AI},
    url = {https://arxiv.org/abs/2501.09686},
}

@misc{yeo2025demystifyinglongchainofthoughtreasoning,
    title = {Demystifying Long Chain-of-Thought Reasoning in LLMs},
    author = {Edward Yeo and Yuxuan Tong and Morry Niu and Graham Neubig and Xiang Yue},
    year = {2025},
    eprint = {2502.03373},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL},
    url = {https://arxiv.org/abs/2502.03373},
}

@misc{chu2025sftmemorizesrlgeneralizes,
    title = {SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training},
    author = {Tianzhe Chu and Yuexiang Zhai and Jihan Yang and Shengbang Tong and Saining Xie and Dale Schuurmans and Quoc V. Le and Sergey Levine and Yi Ma},
    year = {2025},
    eprint = {2501.17161},
    archivePrefix = {arXiv},
    primaryClass = {cs.AI},
    url = {https://arxiv.org/abs/2501.17161},
}

@misc{kimiteam2025kimik15scalingreinforcement,
    title = {Kimi k1.5: Scaling Reinforcement Learning with LLMs},
    author = {Angang Du and Bofei Gao and Bowei Xing and Changjiu Jiang and Cheng Chen and Cheng Li and Chenjun Xiao and Chenzhuang Du and Chonghua Liao and Chuning Tang and Congcong Wang and Dehao Zhang and Enming Yuan and Enzhe Lu and Fengxiang Tang and Flood Sung and Guangda Wei and Guokun Lai and Haiqing Guo and Han Zhu and Hao Ding and Hao Hu and Hao Yang and Hao Zhang and Haotian Yao and Haotian Zhao and Haoyu Lu and Haoze Li and Haozhen Yu and Hongcheng Gao and Huabin Zheng and Huan Yuan and Jia Chen and Jianhang Guo and Jianlin Su and Jianzhou Wang and Jie Zhao and Jin Zhang and Jingyuan Liu and Junjie Yan and Junyan Wu and Lidong Shi and Ling Ye and Longhui Yu and Mengnan Dong and Neo Zhang and Ningchen Ma and Qiwei Pan and Qucheng Gong and Shaowei Liu and Shengling Ma and Shupeng Wei and Sihan Cao and Siying Huang and Tao Jiang and Weihao Gao and Weimin Xiong and Weiran He and Weixiao Huang and Wenhao Wu and Wenyang He and Xianghui Wei and Xianqing Jia and Xingzhe Wu and Xinran Xu and Xinxing Zu and Xinyu Zhou and Xuehai Pan and Y. Charles and Yang Li and Yangyang Hu and Yangyang Liu and Yanru Chen and Yejie Wang and Yibo Liu and Yidao Qin and Yifeng Liu and Ying Yang and Yiping Bao and Yulun Du and Yuxin Wu and Yuzhi Wang and Zaida Zhou and Zhaoji Wang and Zhaowei Li and Zhen Zhu and Zheng Zhang and Zhexu Wang and Zhilin Yang and Zhiqi Huang and Zihao Huang and Ziyao Xu and Zonghan Yang},
    year = {2025},
    eprint = {2501.12599},
    archivePrefix = {arXiv},
    primaryClass = {cs.AI},
    url = {https://arxiv.org/abs/2501.12599},
}

@misc{tinyzero2025,
    author = {Jiayi Pan and Junjie Zhang and Xingyao Wang and Lifan Yuan and Hao Peng and Alane Suhr},
    title = {TinyZero},
    howpublished = {https://github.com/Jiayi-Pan/TinyZero},
    year = {2025}
}

@online{unsloth_train_2025,
    title = {Train your own R1 reasoning model with Unsloth ({GRPO})},
    url = {https://unsloth.ai/blog/r1-reasoning},
    author = {{Unsloth}},
    date = {2025-02-06},
}

@online{patel_stanford_lecture_2024,
	title = {Dylan Patel - Inference Math, Simulation, and {AI} Megaclusters - Stanford {CS} 229S - Autumn 2024},
	url = {https://www.youtube.com/watch?v=hobvps-H38o},
	author = {Patel, Dylan},
	urldate = {2025-02-17},
	date = {2024-11-12},
}

@online{microsoft_wisconsin_2024,
	title = {Microsoft announces \$3.3 billion investment in Wisconsin to spur artificial intelligence innovation and economic growth},
	url = {https://news.microsoft.com/2024/05/08/microsoft-announces-3-3-billion-investment-in-wisconsin-to-spur-artificial-intelligence-innovation-and-economic-growth/},
	abstract = {President Joe Biden to join Microsoft for announcement in Mount Pleasant Editor‚Äôs note ‚Äì May 10, 2024 ‚Äì This press release was updated to include the full name of National Grid Renewables. Mount Pleasant, {WI} ‚Äì May 8, 2024 ‚Äì Microsoft today announced a broad investment package designed to strengthen the role of Southeast Wisconsin [‚Ä¶]},
	author = {{Microsoft}},
	urldate = {2025-02-17},
	date = {2024-05-08},
	langid = {american},
}

@misc{hao2025magamassivegenreaudiencereformulation,
      title={MAGA: MAssive Genre-Audience Reformulation to Pretraining Corpus Expansion},
      author={Xintong Hao and Ke Shen and Chenggang Li},
      year={2025},
      eprint={2502.04235},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.04235},
}

@online{openai_learning_to_reason_with_llms_2024,
	title = {Learning to reason with LLMs},
	url = {https://openai.com/index/learning-to-reason-with-llms/},
	abstract = {We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex reasoning. o1 thinks before it answers‚Äîit can produce a long internal chain of thought before responding to the user.},
	author = {{OpenAI}},
	urldate = {2025-02-23},
	date = {2024-09-12},
}

@online{cnbc_amazon_2025,
	title = {Amazon plans to spend \$100 billion this year to capture ‚Äòonce in a lifetime opportunity‚Äô in {AI}},
	url = {https://www.cnbc.com/2025/02/06/amazon-expects-to-spend-100-billion-on-capital-expenditures-in-2025.html},
	abstract = {Amazon said Thursday it plans to boost its capital expenditures to \$100 billion in 2025, as it continues its spending spree on {AI} services.},
	titleaddon = {{CNBC}},
	author = {{CNBC}},
	urldate = {2025-02-23},
	date = {2025-02-06},
	langid = {english},
}

@online{data_center_dynamics_google_2025,
	title = {Google expects 2025 capex to surge to \$75bn on {AI} data center buildout},
	url = {https://www.datacenterdynamics.com/en/news/google-expects-2025-capex-to-surge-to-75bn-on-ai-data-center-buildout/},
	abstract = {But Google Cloud revenues disappoint, and shares fall},
	author = {{Data Center Dynamics}},
	urldate = {2025-02-23},
	date = {2025-02-05},
	langid = {english},
}

@online{patel_10b_2024,
	title = {\$10B {OpenAI} \& Microsoft Cluster in 2025 ‚Äì Dylan Patel \& @Asianometry},
	url = {https://www.youtube.com/watch?v=J7yvSkIOZLw},
	abstract = {Enjoy the videos and music you love, upload original content, and share it all with friends, family, and the world on {YouTube}.},
	author = {Patel, Dylan},
	urldate = {2025-02-23},
	date = {2024-10-09},
}

@misc{artificial_analysis_2024,
	title = {Artificial Analysis {AI} Review: 2024 Highlights},
	url = {https://artificialanalysis.ai/downloads/ai-review/2024/Artificial-Analysis-AI-Review-2024-Highlights.pdf},
	author = {{Artificial Analysis}},
	date = {2024-12-17},
}

@misc{xiao2024densinglawllms,
      title={Densing Law of LLMs},
      author={Chaojun Xiao and Jie Cai and Weilin Zhao and Guoyang Zeng and Biyuan Lin and Jie Zhou and Zhi Zheng and Xu Han and Zhiyuan Liu and Maosong Sun},
      year={2024},
      eprint={2412.04315},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2412.04315},
}

@online{european_commission_2025,
	title = {{EU} launches {InvestAI} initiative to mobilise ‚Ç¨200 billion of investment in artificial intelligence},
	url = {https://ec.europa.eu/commission/presscorner/detail/en/https:\/\/ec.europa.eu\/commission\/presscorner\/detail\/en\/ip_25_467},
	abstract = {Today, at the Artificial Intelligence ({AI}) Action Summit in Paris, Commission President Ursula von der Leyen has launched {InvestAI}, an initiative to mobilise ‚Ç¨200 billion for investment in {AI}, including a new European fund of ‚Ç¨20 billion for {AI} gigafactories.},
	titleaddon = {European Commission - European Commission},
	type = {Text},
	author = {{European Commission}},
    date = {2025-02-11},
	urldate = {2025-03-01},
}

@online{ucsb_remarks_2025,
	title = {Remarks by the Vice President at the Artificial Intelligence Action Summit in Paris, France {\textbar} The American Presidency Project},
	url = {https://www.presidency.ucsb.edu/documents/remarks-the-vice-president-the-artificial-intelligence-action-summit-paris-france},
	author = {{UCSB}},
	urldate = {2025-03-01},
	date = {2025-02-11},
}

@article{wired_metas_2024,
	title = {Meta‚Äôs Next Llama {AI} Models Are Training on a {GPU} Cluster ‚ÄòBigger Than Anything‚Äô Else},
	issn = {1059-1028},
	url = {https://www.wired.com/story/meta-llama-ai-gpu-training/},
	abstract = {The race for better generative {AI} is also a race for more computing power. On that score, according to {CEO} Mark Zuckerberg, Meta appears to be winning.},
	journaltitle = {Wired},
	author = {{Wired}},
	urldate = {2025-03-02},
	date = {2024-10-30},
	langid = {american},
	keywords = {artificial intelligence, earnings, energy, mark zuckerberg, meta},
}

@online{doe_2024,
	title = {{DOE} Releases New Report Evaluating Increase in Electricity Demand from Data Centers},
	url = {https://www.energy.gov/articles/doe-releases-new-report-evaluating-increase-electricity-demand-data-centers},
	abstract = {Domestic Energy Usage from Data Centers Expected to Double or Triple by 2028, {DOE} Continues to Accelerate Development and Deployment of Solutions to Meet Growing Demand},
	titleaddon = {Energy.gov},
	author = {{DOE}},
	urldate = {2025-03-02},
	date = {2024-12-20},
	langid = {english},
}

@misc{pjm_2025,
	title = {{PJM} Long-Term Load Forecast Report},
	url = {https://www.pjm.com/-/media/DotCom/library/reports-notices/load-forecast/2025-load-report.pdf},
	author = {{PJM}},
	date = {2025-01-24},
}

@online{amazon_principal_2024,
	title = {Principal Nuclear Engineer, Datacenter Engineering, Power Generation Solutions - Job {ID}: 2741394 {\textbar} Amazon.jobs},
	url = {https://web.archive.org/web/20241106092116/https://www.amazon.jobs/en/jobs/2741394/principal-nuclear-engineer-datacenter-engineering-power-generation-solutions},
	shorttitle = {Principal Nuclear Engineer, Datacenter Engineering, Power Generation Solutions - Job {ID}},
	author = {{Amazon}},
	urldate = {2025-03-02},
	date = {2024-11-06},
}

@online{amazon_nuclear_deals_2024,
	title = {Amazon signs agreements for innovative nuclear energy projects to address growing energy demands},
	url = {https://www.aboutamazon.com/news/sustainability/amazon-nuclear-small-modular-reactor-net-carbon-zero},
	abstract = {New Small Modular Reactor agreements are part of Amazon‚Äôs plan to transition to carbon-free energy.},
	author = {{Amazon}},
	urldate = {2025-03-02},
	date = {2024-10-16},
	langid = {english},
}

@online{google_kairos_2024,
	title = {New nuclear clean energy agreement with Kairos Power},
	url = {https://blog.google/outreach-initiatives/sustainability/google-kairos-power-nuclear-energy-agreement/},
	abstract = {Google‚Äôs first nuclear energy deal is a step toward helping the world decarbonize through investments in advanced clean energy technologies.},
	titleaddon = {Google},
	author = {{Google}},
	urldate = {2025-03-02},
	date = {2024-10-14},
	langid = {english},
}

@online{data_center_dynamics_microsoft_2024,
	title = {Microsoft hires Archie Manoharan as director of nuclear technologies, joins from micro modular reactor firm},
	url = {https://www.datacenterdynamics.com/en/news/microsoft-hires-archie-manoharan-as-director-of-nuclear-technologies-joins-from-micro-modular-reactor-firm/},
	abstract = {As company builds out its data center nuclear power team},
	author = {{Data Center Dynamics}},
	urldate = {2025-03-02},
	date = {2024-01-22},
	langid = {english},
}

@online{microsoft_principal_2023,
	title = {Principal Program Manager Nuclear Technology {\textbar} Microsoft Careers},
	url = {https://web.archive.org/web/20230922194154/https://jobs.careers.microsoft.com/global/en/job/1627555/Principal-Program-Manager-Nuclear-Technology},
	author = {{Microsoft}},
	urldate = {2025-03-02},
	date = {2023-09-22},
}

@online{meta_accelerating_2024,
	title = {Accelerating the Next Wave of Nuclear to Power {AI} Innovation},
	url = {https://sustainability.atmeta.com/blog/2024/12/03/accelerating-the-next-wave-of-nuclear-to-power-ai-innovation/},
	abstract = {Meta releases a Request for Proposals ({RFP}) to identify nuclear energy developers to support {AI} innovation and clean and renewable energy goals.},
	titleaddon = {Meta Sustainability},
	author = {{Meta}},
	urldate = {2025-03-02},
	date = {2024-12-03},
	langid = {american},
}

@online{bloomberg_constellation_2024,
	title = {Constellation {CEO} Says {US} Should Copy China to Meet {AI} Power Use},
	url = {https://www.bloomberg.com/news/articles/2024-09-23/constellation-ceo-sees-ai-as-critical-to-us-national-security},
	author = {{Bloomberg}},
	date = {2024-09-23},
}

@online{wall_street_journal_tech_2024,
	title = {Tech Industry Wants to Lock Up Nuclear Power for {AI}},
	url = {https://www.msn.com/en-us/money/other/tech-industry-wants-to-lock-up-nuclear-power-for-ai/ar-BB1pbf4e},
	author = {{Wall Street Journal}},
	urldate = {2025-03-02},
	date = {2024-07-01},
}

@online{data_center_frontier_gigawatt_2024,
	title = {The Gigawatt Data Center Campus is Coming},
	url = {https://www.datacenterfrontier.com/hyperscale/article/55021675/the-gigawatt-data-center-campus-is-coming},
	abstract = {Hyperscale tech companies are seeking campuses that can support 1 gigawatt of electric power capacity. Developers say new approaches to {MegaCampuses} can enable new technologies...},
	titleaddon = {Data Center Frontier},
	author = {{Data Center Frontier}},
	urldate = {2025-03-02},
	date = {2024-04-29},
	langid = {english},
}

@online{tweaktown_nvidia_2024,
	title = {{NVIDIA} Blackwell {GPUs} for {AI} are effectively 'sold out' for the next 12 months},
	url = {https://www.tweaktown.com/news/101054/nvidia-blackwell-gpus-for-ai-are-effectively-sold-out-the-next-12-months/index.html},
	abstract = {With overwhelming demand for cutting-edge {AI} hardware {NVIDIA}'s Blackwell {AI} {GPUs} are 'sold out,' and will be for the next 12 months.},
	titleaddon = {{TweakTown}},
	author = {{TweakTown}},
	urldate = {2025-03-07},
	date = {2024-10-13},
	langid = {american},
}

@misc{artificial_analysis_state_2025,
	title = {State of {AI}: China},
	url = {https://artificialanalysis.ai/downloads/china-report/2025/Artificial-Analysis-State-of-AI-China-Q1-2025.pdf},
	author = {{Artificial Analysis}},
	urldate = {2025-03-08},
	date = {2025},
}

@online{planetary_society_how_2019,
	title = {How much did the Apollo program cost?},
	url = {https://www.planetary.org/space-policy/cost-of-apollo},
	abstract = {A rich data set tracking the costs of Project Apollo, free for public use. Includes unprecedented program-by-program cost breakdowns, facilities‚Ä¶},
	titleaddon = {The Planetary Society},
	author = {{Planetary Society}},
	urldate = {2025-03-08},
	date = {2019-06-14},
	langid = {english},
}

@online{stanford_university_2024,
	title = {The 2024 {AI} Index Report {\textbar} Stanford {HAI}},
	url = {https://hai.stanford.edu/ai-index/2024-ai-index-report},
	abstract = {Welcome to the seventh edition of the {AI} Index report. The 2024 Index is our most comprehensive to date and arrives at an important moment when {AI}‚Äôs influence on society has never been more pronounced.},
	author = {{Stanford University}},
	urldate = {2025-03-08},
	date = {2024},
	langid = {english},
}

@online{epoch_ai_performance_2024,
	title = {Performance improves 12x when switching from {FP}32 to tensor-{INT}8},
	url = {https://epoch.ai/data-insights/hardware-performance-trend},
	abstract = {{GPUs} are typically faster when using tensor cores and number formats optimized for {AI} computing. Compared to using non-tensor {FP}32, {TF}32, tensor-{FP}16, and tensor-{INT}8 provide around 6x, 10x, and 12x greater performance on average in the aggregate performance trends. Some chips achieve even larger speedups. For example, the H100 is 59x faster in {INT}8 than in {FP}32. These improvements account for about half of the overall performance trend improvement since their introduction. Models trained with lower precision formats have become common, especially tensor-{FP}16, as developers take advantage of this boost in performance.},
	titleaddon = {Epoch {AI}},
	author = {{Epoch AI}},
	urldate = {2025-03-09},
	date = {2024-10-23},
	langid = {english},
}

@online{the_verge_microsoft_2024,
	title = {Microsoft made the biggest renewable energy agreement ever to fuel its {AI} ambitions},
	url = {https://www.theverge.com/2024/5/2/24147153/microsoft-ai-data-center-record-renewable-energy-purchase},
	abstract = {It‚Äôs the largest renewable energy deal to date for a single company.},
	titleaddon = {The Verge},
	author = {{The Verge}},
	urldate = {2025-03-09},
	date = {2024-05-02},
	langid = {american},
}

@online{constellation_energy_constellation_2024,
	title = {Constellation to Launch Crane Clean Energy Center, Restoring Jobs and Carbon-Free Power to The Grid},
	url = {https://www.constellationenergy.com/newsroom/2024/Constellation-to-Launch-Crane-Clean-Energy-Center-Restoring-Jobs-and-Carbon-Free-Power-to-The-Grid.html},
	abstract = {Constellation announced today the signing of a 20-year power purchase agreement with Microsoft that will pave the way for the launch of the Crane Clean Energy Center ({CCEC}) and restart of Three Mile Island Unit 1, which operated at industry-leading levels of safety and reliability for decades before being shut down for economic reasons exactly five years ago today.},
	author = {{Constellation Energy}},
	urldate = {2025-03-09},
	date = {2024-09-20},
	langid = {english},
}
